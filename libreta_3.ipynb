{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRETA 3: Entrenamiento y evaluacion de modelos\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de esta libreta es producir un generador de texto como hablo. esto esta patentado como \"Amblobot_2000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(text):\n",
    "    tokens = re.split(\"\\\\s+\", text)\n",
    "    ngrams = []\n",
    "    \n",
    "    for i in range(len(tokens)):\n",
    "        temp = [tokens[j] for j in range(i, i+1)]\n",
    "        ngrams.append(\" \".join(temp))\n",
    "    return ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openfile(filename):\n",
    "    # Abre el archivo en modo lectura y crea una lista vacía para almacenar las sentencias\n",
    "    with open(filename, \"r\") as f:\n",
    "        sentencias = []\n",
    "        # Divide el archivo en filas utilizando readlines()\n",
    "        filas = f.readlines()\n",
    "\n",
    "        # Itera sobre cada fila en el archivo\n",
    "        for fila in filas:\n",
    "            # Utiliza una expresión regular para dividir la fila en sentencias\n",
    "            sentencias_en_fila = re.split(\"[?!]+\", fila.strip())\n",
    "\n",
    "            # Agrega cada sentencia a la lista de sentencias\n",
    "            for sentencia in sentencias_en_fila:\n",
    "                if sentencia != \"\":\n",
    "                    sentencias.append(sentencia)\n",
    "    return sentencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bueno, vamos a iniciar la semana como siempre, con el informe de Quién es Quién en los precios. Ricardo Sheffield nos va a poner al día de cómo están los precios de las gasolinas, el diésel, del gas.',\n",
       " 'Nosotros somos estrictos para que no se afecte el medio ambiente en general, no se permite que se contamine en el mar, en tierra, y ya no hay privilegios, no existe impunidad para nadie, trátese de quien se trate.',\n",
       " 'Entonces, decirles a las madres, a los padres de los niños que estamos sobre eso, procurando que nunca les falten los medicamentos.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentencias = openfile(\"corpus_train_auxiliar.txt\")\n",
    "sentencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Bueno,',\n",
       "  'vamos',\n",
       "  'a',\n",
       "  'iniciar',\n",
       "  'la',\n",
       "  'semana',\n",
       "  'como',\n",
       "  'siempre,',\n",
       "  'con',\n",
       "  'el',\n",
       "  'informe',\n",
       "  'de',\n",
       "  'Quién',\n",
       "  'es',\n",
       "  'Quién',\n",
       "  'en',\n",
       "  'los',\n",
       "  'precios.',\n",
       "  'Ricardo',\n",
       "  'Sheffield',\n",
       "  'nos',\n",
       "  'va',\n",
       "  'a',\n",
       "  'poner',\n",
       "  'al',\n",
       "  'día',\n",
       "  'de',\n",
       "  'cómo',\n",
       "  'están',\n",
       "  'los',\n",
       "  'precios',\n",
       "  'de',\n",
       "  'las',\n",
       "  'gasolinas,',\n",
       "  'el',\n",
       "  'diésel,',\n",
       "  'del',\n",
       "  'gas.'],\n",
       " ['Nosotros',\n",
       "  'somos',\n",
       "  'estrictos',\n",
       "  'para',\n",
       "  'que',\n",
       "  'no',\n",
       "  'se',\n",
       "  'afecte',\n",
       "  'el',\n",
       "  'medio',\n",
       "  'ambiente',\n",
       "  'en',\n",
       "  'general,',\n",
       "  'no',\n",
       "  'se',\n",
       "  'permite',\n",
       "  'que',\n",
       "  'se',\n",
       "  'contamine',\n",
       "  'en',\n",
       "  'el',\n",
       "  'mar,',\n",
       "  'en',\n",
       "  'tierra,',\n",
       "  'y',\n",
       "  'ya',\n",
       "  'no',\n",
       "  'hay',\n",
       "  'privilegios,',\n",
       "  'no',\n",
       "  'existe',\n",
       "  'impunidad',\n",
       "  'para',\n",
       "  'nadie,',\n",
       "  'trátese',\n",
       "  'de',\n",
       "  'quien',\n",
       "  'se',\n",
       "  'trate.'],\n",
       " ['Entonces,',\n",
       "  'decirles',\n",
       "  'a',\n",
       "  'las',\n",
       "  'madres,',\n",
       "  'a',\n",
       "  'los',\n",
       "  'padres',\n",
       "  'de',\n",
       "  'los',\n",
       "  'niños',\n",
       "  'que',\n",
       "  'estamos',\n",
       "  'sobre',\n",
       "  'eso,',\n",
       "  'procurando',\n",
       "  'que',\n",
       "  'nunca',\n",
       "  'les',\n",
       "  'falten',\n",
       "  'los',\n",
       "  'medicamentos.']]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = []\n",
    "for sentencia in sentencias:\n",
    "    text.append(split(sentencia))\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bueno,', 'vamos'),\n",
       " ('vamos', 'a'),\n",
       " ('a', 'iniciar'),\n",
       " ('iniciar', 'la'),\n",
       " ('la', 'semana'),\n",
       " ('semana', 'como'),\n",
       " ('como', 'siempre,'),\n",
       " ('siempre,', 'con'),\n",
       " ('con', 'el'),\n",
       " ('el', 'informe'),\n",
       " ('informe', 'de'),\n",
       " ('de', 'Quién'),\n",
       " ('Quién', 'es'),\n",
       " ('es', 'Quién'),\n",
       " ('Quién', 'en'),\n",
       " ('en', 'los'),\n",
       " ('los', 'precios.'),\n",
       " ('precios.', 'Ricardo'),\n",
       " ('Ricardo', 'Sheffield'),\n",
       " ('Sheffield', 'nos'),\n",
       " ('nos', 'va'),\n",
       " ('va', 'a'),\n",
       " ('a', 'poner'),\n",
       " ('poner', 'al'),\n",
       " ('al', 'día'),\n",
       " ('día', 'de'),\n",
       " ('de', 'cómo'),\n",
       " ('cómo', 'están'),\n",
       " ('están', 'los'),\n",
       " ('los', 'precios'),\n",
       " ('precios', 'de'),\n",
       " ('de', 'las'),\n",
       " ('las', 'gasolinas,'),\n",
       " ('gasolinas,', 'el'),\n",
       " ('el', 'diésel,'),\n",
       " ('diésel,', 'del'),\n",
       " ('del', 'gas.')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(bigrams(text[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
